{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     C:\\Users\\Naman Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     C:\\Users\\Naman Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     C:\\Users\\Naman Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     C:\\Users\\Naman Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     C:\\Users\\Naman Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     C:\\Users\\Naman Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package verbnet to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet3 to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ycoe is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rslp is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     C:\\Users\\Naman Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     C:\\Users\\Naman Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\Naman Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package sample_grammars to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     C:\\Users\\Naman Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package large_grammars to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     C:\\Users\\Naman Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package word2vec_sample to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\Naman Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     C:\\Users\\Naman Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package perluniprops to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     C:\\Users\\Naman Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data]    | Downloading package vader_lexicon to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package porter_test to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package porter_test is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
      "[nltk_data]    | Downloading package mwa_ppdb to C:\\Users\\Naman\n",
      "[nltk_data]    |     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input Doc**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1='''Web mining is the application of data mining techniques to discover patterns from the World Wide Web.\n",
    "As the name proposes, this is information gathered by mining the web. It makes utilization of automated apparatuses \n",
    "to reveal and extricate data from servers and web2 reports, and it permits organizations to get to both organized and \n",
    "unstructured information from browser activities, server logs, website and link structure, page content and different sources.\n",
    "The goal of Web structure mining is to generate structural summary about the Web site and Web page. Technically, Web content \n",
    "mining mainly focuses on the structure of inner-document, while Web structure mining tries to discover the link structure of \n",
    "the hyperlinks at the inter-document level. Based on the topology of the hyperlinks, Web structure mining will categorize \n",
    "the Web pages and generate the information, such as the similarity and relationship between different \n",
    "Web sites.Web structure mining can also have another direction – discovering the structure of Web document itself. \n",
    "This type of structure mining can be used to reveal the structure (schema) of Web pages, this would be good for navigation purpose \n",
    "and make it possible to compare/integrate Web page schemes.'''\n",
    "doc2='''Web scraping, web harvesting, or web data extraction is data scraping used for extracting data from websites. \n",
    "Web scraping software may access the World Wide Web directly using the Hypertext Transfer Protocol, or through a web browser. \n",
    "While web scraping can be done manually by a software user, the term typically refers to automated processes implemented using \n",
    "a bot or web crawler. It is a form of copying, in which specific data is gathered and copied from the web, typically into a \n",
    "central local database or spreadsheet, for later retrieval or analysis.Web scraping a web page involves fetching it and \n",
    "extracting from it. Fetching is the downloading of a page (which a browser does when a user views a page). Therefore, web\n",
    "crawling is a main component of web scraping, to fetch pages for later processing. Once fetched, then extraction can take place. \n",
    "The content of a page may be parsed, searched, reformatted, its data copied into a spreadsheet, and so on. Web scrapers \n",
    "typically take something out of a page, to make use of it for another purpose somewhere else. An example would be to find \n",
    "and copy names and phone numbers, or companies and their URLs, to a list (contact scraping).Web scraping is used for \n",
    "contact scraping, and as a component of applications used for web indexing, web mining and data mining, online price\n",
    "change monitoring and price comparison, product review scraping (to watch the competition), gathering real estate \n",
    "listings, weather data monitoring, website change detection, research, tracking online presence and reputation, web mashup and\n",
    ", web data integration.Web pages are built using text-based mark-up languages (HTML and XHTML), and frequently contain\n",
    "a wealth of useful data in text form. However, most web pages are designed for human end-users and not for ease of automated use.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With stemming**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "LS=LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'web min is the apply of dat min techn to discov pattern from the world wid web. as the nam proposes, thi is inform gath by min the web. it mak util of autom apparatus to rev and ext dat from serv and web2 reports, and it permit org to get to both org and unstruct inform from brows activities, serv logs, websit and link structure, pag cont and diff sources. the goal of web structure min is to gen structural sum about the web sit and web page. technically, web cont min main focus on the structure of inner-document, whil web structure min tri to discov the link structure of the hyperlink at the inter-document level. bas on the topolog of the hyperlinks, web structure min wil categ the web pag and gen the information, such as the simil and rel between diff web sites.web structure min can also hav anoth direct – discov the structure of web docu itself. thi typ of structure min can be us to rev the structure (schema) of web pages, thi would be good for navig purpos and mak it poss to compare/integrat web pag schemes.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Stem1formed=[LS.stem(i) for i in doc1.split()]\n",
    "Stem1formed=\" \".join(Stem1formed)\n",
    "Stem1formed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'web scraping, web harvesting, or web dat extract is dat scraping us for extract dat from websites. web scraping softw may access the world wid web direct us the hypertext transf protocol, or through a web browser. whil web scraping can be don man by a softw user, the term typ ref to autom process impl us a bot or web crawler. it is a form of copying, in which spec dat is gath and cop from the web, typ into a cent loc databas or spreadsheet, for lat retriev or analysis.web scraping a web pag involv fetch it and extract from it. fetch is the download of a pag (which a brows doe when a us view a page). therefore, web crawl is a main compon of web scraping, to fetch pag for lat processing. ont fetched, then extract can tak place. the cont of a pag may be parsed, searched, reformatted, it dat cop into a spreadsheet, and so on. web scrapers typ tak someth out of a page, to mak us of it for anoth purpos somewh else. an exampl would be to find and cop nam and phon numbers, or company and their urls, to a list (contact scraping).web scraping is us for contact scraping, and as a compon of apply us for web indexing, web min and dat mining, onlin pric chang monit and pric comparison, produc review scraping (to watch the competition), gath real est listings, weath dat monitoring, websit chang detection, research, track onlin pres and reputation, web mashup and , web dat integration.web pag ar built us text-based mark-up langu (html and xhtml), and frequ contain a weal of us dat in text form. however, most web pag ar design for hum end-users and not for eas of autom use.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Stem2formed=[LS.stem(i) for i in doc2.split()]\n",
    "Stem2formed=\" \".join(Stem2formed)\n",
    "Stem2formed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect=CountVectorizer(binary=True)\n",
    "corpusformed = [Stem1formed,Stem2formed]\n",
    "vect.fit(corpusformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab=vect.vocabulary_\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.296923]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similar = cosine_similarity(vect.transform([Stem1formed]).toarray(), vect.transform([Stem2formed]).toarray())\n",
    "similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Without Stemming**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect=CountVectorizer(binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusnostem = [doc1,doc2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.fit(corpusnostem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab=vect.vocabulary_\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.26048132]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity = cosine_similarity(vect.transform([doc1]).toarray(), vect.transform([doc2]).toarray())\n",
    "similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results:**\n",
    "**With Stemming:** \n",
    "  * Vocab = 212\n",
    "  * Similarity = 0.296923\n",
    "\n",
    "**Without Stemming:** \n",
    "  * Vocab = 220\n",
    "  * Similarity = 0.26048132\n",
    "\n",
    "\n",
    "**We can observe an increase in Cosine Similarity with Stemming. Also the vocabulary size decreases on stemming as multiple words with the same root are eliminated.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
